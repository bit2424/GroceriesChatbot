version: '3'

services:
  llm-finetuning:
    image: tensorflow/tensorflow:latest-gpu
    volumes:
      - .:/app
    working_dir: /app
    # Command to keep the container running
    command: ["tail", "-f", "/dev/null"]
