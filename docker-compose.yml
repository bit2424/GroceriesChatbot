version: '3'

services:
  llm-finetuning:
    build: .
    volumes:
      - .:/app
    working_dir: /app
    
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            capabilities: [gpu]

    # Command to keep the container running
    command: ["tail", "-f", "/dev/null"]
